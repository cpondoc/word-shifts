{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b85fe7b-cd51-4a14-8079-2a6146d72adf",
   "metadata": {},
   "source": [
    "# CS 224N - WinoDict Evaluation using RoBERTa Embeddings\n",
    "Evaluating on WinoDict task using RoBERTa finetuned to predict GPT-2 embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02be948f-5392-44a7-b250-597527e3f474",
   "metadata": {},
   "source": [
    "## Setting up PyTorch\n",
    "Using PyTorch on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b013644-fe9c-4c94-bc13-4d28c4a6c617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using GPU: \" + str(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edda494-e0d9-4d00-88e3-3869f8392c33",
   "metadata": {},
   "source": [
    "## Load in WinoDict Dataset\n",
    "Load in the first generated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d6e85f1-5074-4788-8b3c-a3e0f6f7b484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first_set = pd.read_csv(\"winodict/prob1_of_5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9e2fa-2789-429b-8f33-1ffb84805e37",
   "metadata": {},
   "source": [
    "## Check Definitions of Words in Wordset\n",
    "With old Wordset dataset, check if they end up existing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094721d5-ff36-43e7-a4e0-320e5d3a3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def find_definition(word):\n",
    "    # Load in the data for the first letter\n",
    "    letter = word[0]\n",
    "    f = open('dictionary/' + letter + '.json')\n",
    "    data = json.load(f)\n",
    "    \n",
    "    # Look through each of the definitions\n",
    "    definition = \"\"\n",
    "    if (word in data.keys()):\n",
    "        if ('meanings' in data[word]):\n",
    "            for index in range(len(data[word]['meanings'])):\n",
    "                definition += data[word]['meanings'][index]['def'] + \". \"\n",
    "    \n",
    "    return definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21809b-a2f7-4c40-8a69-69683a08f207",
   "metadata": {},
   "source": [
    "## Grab GPT-2 and RoBERTa\n",
    "Look at GPT-2 and RoBERTa fine-tuned for downstream task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4427bc2a-0605-42b2-9b15-5d46dc31753e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AutoTokenizer, RobertaModel\n",
    "\n",
    "# GPT-2 Model and Tokenizer\n",
    "ro_model = GPT2LMHeadModel.from_pretrained(\"weights/G2GNext1\").to(\"cuda\")\n",
    "ro_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")\n",
    "ro_tokenizer.add_tokens(['[CLS]']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a913fd-ed9a-47be-81e8-df415ddce4e5",
   "metadata": {},
   "source": [
    "## Turning Fake Words into Embeddings in GPT-2!\n",
    "Using a standard GPT-2 model, added the new word embedding specifically for the fake word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31a8c6c-9cf1-42ab-963b-20d8e8d73868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_word_into_embedding(replacement, fake_word):\n",
    "    # GPT-2 Model and Tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2-medium').to(\"cuda\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "    \n",
    "    # Get definition of the word\n",
    "    definition = find_definition(replacement)\n",
    "    \n",
    "    # Adding the next word\n",
    "    if (definition != \"\"):\n",
    "        # Pass into the tokenizer\n",
    "        ro_tokenizer.pad_token = tokenizer.eos_token\n",
    "        tokenized_input = ro_tokenizer(definition, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=511).to(\"cuda\")\n",
    "        tokenized_cls = ro_tokenizer(\" [CLS]\", return_tensors=\"pt\").to(\"cuda\")\n",
    "        tokenized_input['input_ids'] = torch.cat((tokenized_input['input_ids'], tokenized_cls['input_ids']), dim=1).to(\"cuda\")\n",
    "        \n",
    "        # Pass into the model and extract the predicted embedding\n",
    "        outputs = ro_model(input_ids=tokenized_input['input_ids'].to(\"cuda\"), output_hidden_states=True)\n",
    "        last_hidden = outputs.hidden_states[-1][:,511,:]\n",
    "        predicted_embedding = last_hidden.squeeze(0)\n",
    "        \n",
    "        # Add the new token and resize the model embedding\n",
    "        tokenizer.add_tokens([fake_word])\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        # Get model parameters and embeddings\n",
    "        params = model.state_dict()\n",
    "        embeddings = params['transformer.wte.weight']\n",
    "        \n",
    "        # Update with the new embedding\n",
    "        embeddings[-1:,:] = predicted_embedding\n",
    "        params['transformer.wte.weight'][-1:,:] = predicted_embedding\n",
    "        model.load_state_dict(params)\n",
    "    \n",
    "    # Done!\n",
    "    print(\"Finished with creating the new model and tokenizer\")\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64f00f-e123-480c-b8c4-b2e32f6d5a24",
   "metadata": {},
   "source": [
    "## Evaluating WinoDict on One Example\n",
    "Writing a function that is reusable and works for one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d392d63-b221-4898-ade9-11a8e0293805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_winodict(example):\n",
    "    # First, replace the word with each of the options\n",
    "    if ('_' in example['sentence']):\n",
    "        # Get the correct evaluation model\n",
    "        model, tokenizer = fake_word_into_embedding(example['lemma'], example['fake_lemma'])\n",
    "        \n",
    "        # Change 'the' to lowercase\n",
    "        first_choice, second_choice = example['option1'], example['option2']\n",
    "        if (first_choice[:4] == \"The \"):\n",
    "            first_choice = \"the \" + first_choice[4:]\n",
    "        if (second_choice[:4] == \"The \"):\n",
    "            second_choice = \"the \" + second_choice[4:]\n",
    "\n",
    "        # Replace the text\n",
    "        first_text, second_text = example['sentence'], example['sentence']\n",
    "        pronoun_loc = example['sentence'].index('_')\n",
    "        first_option = example['definition'] + \" \" + first_text[:pronoun_loc] + first_choice + first_text[pronoun_loc + 1:]\n",
    "        second_option = example['definition'] + \" \" + second_text[:pronoun_loc] + second_choice + second_text[pronoun_loc + 1:]\n",
    "\n",
    "        # Tokenize each string and produce labels\n",
    "        first_inputs, second_inputs = tokenizer(first_option, return_tensors=\"pt\").to(\"cuda\"), tokenizer(second_option, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "        # Create the first token labels\n",
    "        first_masked_tokens = tokenizer(example['definition'] + \" \" + first_text[:pronoun_loc] + first_choice, return_tensors=\"pt\").to(\"cuda\")\n",
    "        first_labels = first_masked_tokens[\"input_ids\"][0].to(\"cuda\")\n",
    "        first_mask = torch.full((1, first_labels.shape[0]), -100).to(\"cuda\")\n",
    "        first_fill = tokenizer(first_text[pronoun_loc + 1:], return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "        final_first_labels = torch.cat((first_mask, first_fill), dim=1).to(\"cuda\")\n",
    "\n",
    "        # Create the second token labels\n",
    "        second_masked_tokens = tokenizer(example['definition'] + \" \" + second_text[:pronoun_loc] + second_choice, return_tensors=\"pt\").to(\"cuda\")\n",
    "        second_labels = second_masked_tokens[\"input_ids\"][0].to(\"cuda\")\n",
    "        second_mask = torch.full((1, second_labels.shape[0]), -100).to(\"cuda\")\n",
    "        second_fill = tokenizer(second_text[pronoun_loc + 1:], return_tensors=\"pt\")[\"input_ids\"].to(\"cuda\")\n",
    "        final_second_labels = torch.cat((second_mask, second_fill), dim=1).to(\"cuda\")\n",
    "\n",
    "        # Evaluate the model on each example and check\n",
    "        first_loss = model(**first_inputs, labels=final_first_labels).loss\n",
    "        second_loss = model(**second_inputs, labels=final_second_labels).loss\n",
    "        \n",
    "        # Write down the correct value and check\n",
    "        if (first_loss < second_loss):\n",
    "            print(\"Finished Evaluation\")\n",
    "            return (int(example['label']) == 0)\n",
    "        else:\n",
    "            print(\"Finished Evaluation\")\n",
    "            return (int(example['label']) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f58a5-d491-429c-9a3e-66a78766f67a",
   "metadata": {},
   "source": [
    "## Evaluating Winograd on GPT-2\n",
    "Looking specifically at `WinoDict`, with the first generated examples and adding in the definition and substituting in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcd9783-aaab-4cc4-8894-4a9faac71c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with creating the new model and tokenizer\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithCrossAttentions' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemma\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      4\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_winodict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(correct)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(total)\n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mevaluate_winodict\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     35\u001b[0m final_second_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((second_mask, second_fill), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate the model on each example and check\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m first_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfirst_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_first_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     39\u001b[0m second_loss \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msecond_inputs, labels\u001b[38;5;241m=\u001b[39mfinal_second_labels)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Write down the correct value and check\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CausalLMOutputWithCrossAttentions' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "correct, total = 0, 0\n",
    "for index, row in first_set.iterrows():\n",
    "    if (row['lemma'] != \"lemma\"):\n",
    "        total += 1\n",
    "        correct += evaluate_winodict(row)\n",
    "        print(correct)\n",
    "        print(total)\n",
    "        print(\"\")\n",
    "    \n",
    "print(\"GPT-2 Medium achieved a score of: \" + str(float(correct) / float(total)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

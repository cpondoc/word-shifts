{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import WinoDict Dataset\n",
    "Used so that we don't have the overlapping definitions from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "first_set = pd.read_csv(\"winodict/prob1_of_5.csv\")\n",
    "winodict_words = first_set['lemma'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in CBT Data and make CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cbt (/home/ubuntu/.cache/huggingface/datasets/cbt/CN/1.1.0/73e4c9316b0d86a7addd7f80183fb971a6161fa2f8b746da034e205b7e16f78d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc79ddc2f904f638e794574a7a9c9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cbt (/home/ubuntu/.cache/huggingface/datasets/cbt/NE/1.1.0/73e4c9316b0d86a7addd7f80183fb971a6161fa2f8b746da034e205b7e16f78d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f7924c297a41e8ae2fce96525ad6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cbt (/home/ubuntu/.cache/huggingface/datasets/cbt/P/1.1.0/73e4c9316b0d86a7addd7f80183fb971a6161fa2f8b746da034e205b7e16f78d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeae8967f67342e99b3514db56227e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cbt (/home/ubuntu/.cache/huggingface/datasets/cbt/V/1.1.0/73e4c9316b0d86a7addd7f80183fb971a6161fa2f8b746da034e205b7e16f78d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0fa2b2ba274ccbacbbcb83816461a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "cn_dataset_dict = load_dataset(\"cbt\", \"CN\")\n",
    "ne_dataset_dict = load_dataset(\"cbt\", \"NE\")\n",
    "p_dataset_dict = load_dataset(\"cbt\", \"P\")\n",
    "v_dataset_dict = load_dataset(\"cbt\", \"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7622584818649da8abbbb5b6f13cb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/121 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6480b37304da409b86dfbdbcfd8bb453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/109 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a7775d616a436b8c78c2aa1cd82250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/335 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d447716bc754d4ebc1d6ee730e00d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/106 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "252460489"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_dataset_dict[\"train\"].to_csv(\"cbt_extract/cn_train_info.csv\")\n",
    "ne_dataset_dict[\"train\"].to_csv(\"cbt_extract/ne_train_info.csv\")\n",
    "p_dataset_dict[\"train\"].to_csv(\"cbt_extract/p_train_info.csv\")\n",
    "v_dataset_dict[\"train\"].to_csv(\"cbt_extract/v_train_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate Through CSV Files to see what fake words are contained in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "cn_df = pd.read_csv(\"cbt_extract/cn_train_info.csv\")\n",
    "\n",
    "row_list = []\n",
    "added = 0\n",
    "\n",
    "winodict_set = set(winodict_words)\n",
    "\n",
    "for index, row in cn_df.iterrows():\n",
    "    if added == 5000:\n",
    "        break\n",
    "    appeared_wino = []\n",
    "    for word in winodict_set:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in row[\"sentences\"]:\n",
    "            appeared_wino.append(word)\n",
    "    if appeared_wino == []:\n",
    "        continue\n",
    "    appeared_wino = [w.strip() for w in appeared_wino]\n",
    "    new_row_dict = {\"sentences\": row[\"sentences\"], \"question\": row[\"question\"], \"answer\": row[\"answer\"],\"options\": row[\"options\"], \"winodict_words\": appeared_wino, \"group\": \"CN\"}\n",
    "    row_list.append(new_row_dict)\n",
    "    added += 1\n",
    "\n",
    "added = 0\n",
    "ne_df = pd.read_csv(\"cbt_extract/ne_train_info.csv\")\n",
    "for index, row in ne_df.iterrows():\n",
    "    if added == 5000:\n",
    "        break\n",
    "    appeared_wino = []\n",
    "    for word in winodict_set:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in row[\"sentences\"]:\n",
    "            appeared_wino.append(word)\n",
    "    if appeared_wino == []:\n",
    "        continue\n",
    "    appeared_wino = [w.strip() for w in appeared_wino]\n",
    "    new_row_dict = {\"sentences\": row[\"sentences\"], \"question\": row[\"question\"], \"answer\": row[\"answer\"],\"options\": row[\"options\"], \"winodict_words\": appeared_wino, \"group\": \"NE\"}\n",
    "    row_list.append(new_row_dict)\n",
    "    added += 1\n",
    "\n",
    "added = 0\n",
    "p_df = pd.read_csv(\"cbt_extract/p_train_info.csv\")\n",
    "for index, row in p_df.iterrows():\n",
    "    if added == 5000:\n",
    "        break\n",
    "    appeared_wino = []\n",
    "    for word in winodict_set:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in row[\"sentences\"]:\n",
    "            appeared_wino.append(word)\n",
    "    if appeared_wino == []:\n",
    "        continue\n",
    "    appeared_wino = [w.strip() for w in appeared_wino]\n",
    "    new_row_dict = {\"sentences\": row[\"sentences\"], \"question\": row[\"question\"], \"answer\": row[\"answer\"],\"options\": row[\"options\"], \"winodict_words\": appeared_wino, \"group\": \"P\"}\n",
    "    row_list.append(new_row_dict)\n",
    "    added += 1\n",
    "\n",
    "added = 0\n",
    "v_df = pd.read_csv(\"cbt_extract/v_train_info.csv\")\n",
    "for index, row in v_df.iterrows():\n",
    "    if added == 5000:\n",
    "        break\n",
    "    appeared_wino = []\n",
    "    for word in winodict_set:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in row[\"sentences\"]:\n",
    "            appeared_wino.append(word)\n",
    "    if appeared_wino == []:\n",
    "        continue\n",
    "    appeared_wino = [w.strip() for w in appeared_wino]\n",
    "    new_row_dict = {\"sentences\": row[\"sentences\"], \"question\": row[\"question\"], \"answer\": row[\"answer\"],\"options\": row[\"options\"], \"winodict_words\": appeared_wino, \"group\": \"V\"}\n",
    "    row_list.append(new_row_dict)\n",
    "    added += 1\n",
    "\n",
    "\n",
    "with open(\"updated_cbt_extract/updated_cbt_info.csv\", \"w\") as f:\n",
    "    w = csv.DictWriter(f, [\"sentences\",\"question\",\"answer\",\"options\",\"winodict_words\",\"group\"])\n",
    "    w.writeheader()\n",
    "    for entry in row_list:\n",
    "        w.writerow(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replied the XXXXX ; for the king 's aunts were old-fashioned , and did not approve of her , and she knew it .\n",
      "replied the queen ; for the XXXXX 's aunts were old-fashioned , and did not approve of her , and she knew it .\n",
      "replied the queen ; for the king 's XXXXX were old-fashioned , and did not approve of her , and she knew it .\n",
      "`` They are very kind old ladies in their way , '' said the XXXXX ; `` and were nice to me when I was a boy . ''\n",
      "`` They are very kind old ladies in their way , '' said the king ; `` and were nice to me when I was a XXXXX . ''\n",
      "Then he waited a little , and remarked : `` The XXXXX , of course , you have invited ?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m cbt_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cbt_df = pd.read_csv(\"updated_cbt_extract/updated_cbt_info.csv\")\n",
    "\n",
    "for index, row in cbt_df.iterrows():\n",
    "    print(row[\"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the Dataframe to have a different ordering of answers (so not first 2500 cn, next 2500 ne, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbt_df = pd.read_csv(\"updated_cbt_extract/updated_cbt_info.csv\")\n",
    "cbt_df = cbt_df.sample(frac=1).reset_index(drop=True)\n",
    "cbt_df.to_csv(\"updated_cbt_extract/updated_cbt_info.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
